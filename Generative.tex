\section{Generative models}
\subsection*{Variational AEs}
$\mathbb{E}_x[f(x)]=\mathbb{E}_z[f(F_\theta(z))]$ law of the unconscious stat. \\
$\textbf{ELBO}(\phi, \theta)=\mathbb{E}_{z\sim q_\phi(z\vert x)}[log p_\theta (x\vert z)] - D_{\textbf{KL}}(q_\phi (z \vert x) \| p_\theta (z))$, $p_\theta (z)$ chosen prior. \\
$\nabla_\theta \mathbb{E}_{q_\phi}[log p_\theta (x\vert z)] \stackrel{\textit{Leibniz}}{=}  \mathbb{E}_{q_\phi}[\nabla_\theta log p_\theta (x\vert z)] \approx \frac{1}{N}\sum_{n\leq N} \nabla_\theta log p_\theta (x\vert z^{(n)}), z^{(n)} \sim q_\phi(.\vert x)$ \\
$\nabla_\phi \mathbb{E}_{q_\phi}[L(x,z)] =  \mathbb{E}_{q_\phi}[L(x,z)\nabla_\phi q_\phi(z\vert x)]$, (reinforcement trick) but high variance! $\rightarrow$ reparam.\\
$\nabla_\phi \mathbb{E}_{q_\phi}[L(x,z)] =  \mathbb{E}_{\epsilon}[\nabla_\phi L(x, g_\phi(\epsilon))]$ estimated via MC sampling \\
$z\sim \mathcal{N}(\mu, C),\, \nabla_\mu \mathbb{E}[f(z)] = \mathbb{E}[\nabla_z f(z)]$, (Bonnet)\\
$\nabla_U \mathbb{E}[f(z)] = \mathbb{E}_\epsilon[\epsilon^\top g], g := \nabla_\xi f(\xi) \vert_{\xi + U\epsilon + \mu} $

\subsection*{GANs}
Baye's optimal classifier: $q_\theta(x) = p / (p + p_\theta)$ 
Objective: $\mathbb{E}_{\tilde p_\theta}[y ln(q_\theta(x) + (1-y)ln(1-q_\theta(x)))]$ \\
\textbf{Optimizing GANs}: saddle-points problem, mode-collapse, unstability,... WIP
